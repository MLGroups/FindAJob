## 一：数据结构
### 1.链表

*比较顺序表和链表的优缺点，说说它们分别在什么场景下使用？*

    链表：
     {
       缺点：需要多余的空间存储指针。
             存取某个元素速度慢，需要遍历。
       优点：插入元素和删除元素速度快。
      没有空间限制,存储元素的个数无上限,基本只与内存空间大小有关
     }

    顺序表：
    {
       优点：空间利用率高。
      存取某个元素速度快（直接靠下标即可）
       缺点：插入元素和删除元素存在元素移动,速度慢,耗时。
      有空间限制,当需要存取的元素个数可能多于顺序表的元素个数时,会出现"溢出"问题.当元素个数远少于预先分配的空间时,空间浪费巨大.
    }
    总结：频繁的插入、删除数据时应用链表。

题目：
1. 求单链表中结点的个数
2. 将单链表反转
3. 查找单链表中的倒数第K个结点（k > 0）
4. 查找单链表的中间结点
5. 从尾到头打印单链表
6. 已知两个单链表pHead1 和pHead2 各自有序，把它们合并成一个链表依然有序
7. 判断一个单链表中是否有环
8. 判断两个单链表是否相交
9. 求两个单链表相交的第一个节点
10. 已知一个单链表中存在环，求进入环中的第一个节点
11. 给出一单链表头指针pHead和一节点指针pToBeDeleted，O(1)时间复杂度删除节点pToBeDeleted

### 2.二叉树
已知两种遍历序列，求另一种遍历序列。

二叉树各度节点数关系：

    n:节点总数，n0～n2：度为0～2的节点数

    n = n0 + n1 + n2
    n = n1 + 2 * n2 + 1
    n0 = n2 + 1

### 3.栈和队列
常见栈的应用场景包括括号问题的求解，表达式的转换和求值，函数调用和递归实现，深度优先搜索遍历等；

常见的队列的应用场景包括计算机系统中各种资源的管理，消息缓冲器的管理和广度优先搜索遍历等。

### 4.内存中的堆栈
https://blog.csdn.net/liu_yude/article/details/45058687

堆：顺序随意

栈：先进后出

一个由c/C++编译的程序占用的内存分为以下几个部分

1、栈区（stack）— 由编译器自动分配释放 ，存放函数的参数值，局部变量的值等。其操作方式类似于数据结构中的栈。

2、堆区（heap） — 一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收 。注意它与数据结构中的堆是两回事，分配方式倒是类似于链表，呵呵。

3、全局区（静态区）（static）—，全局变量和静态变量的存储是放在一块的，初始化的全局变量和静态变量在一块区域， 未初始化的全局变量和未初始化的静态变量在相邻的另一块区域。 - 程序结束后有系统释放

4、文字常量区 —常量字符串就是放在这里的。 程序结束后由系统释放

5、程序代码区—存放函数体的二进制代码。

### 5.图



## 二：计算机网络
http://www.cnblogs.com/zyf-zhaoyafei/p/4716297.html

### 1.三次握手，四次挥手
#### 三次握手：

第一次握手：客户端发送syn包(syn=x)到服务器，并进入SYN_SEND状态，等待服务器确认；

第二次握手：服务器收到syn包，必须确认客户的SYN（ack=x+1），同时自己也发送一个SYN包（syn=y），即SYN+ACK包，此时服务器进入SYN_RECV状态；

第三次握手：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=y+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。

握手过程中传送的包里不包含数据，三次握手完毕后，客户端与服务器才正式开始传送数据。理想状态下，TCP连接一旦建立，在通信双方中的任何一方主动关闭连接之前，TCP 连接都将被一直保持下去。

#### 四次挥手

与建立连接的“三次握手”类似，断开一个TCP连接则需要“四次挥手”。

第一次挥手：主动关闭方发送一个FIN，用来关闭主动方到被动关闭方的数据传送，也就是主动关闭方告诉被动关闭方：我已经不 会再给你发数据了(当然，在fin包之前发送出去的数据，如果没有收到对应的ack确认报文，主动关闭方依然会重发这些数据)，但是，此时主动关闭方还可 以接受数据。

第二次挥手：被动关闭方收到FIN包后，发送一个ACK给对方，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号）。

第三次挥手：被动关闭方发送一个FIN，用来关闭被动关闭方到主动关闭方的数据传送，也就是告诉主动关闭方，我的数据也发送完了，不会再给你发数据了。

第四次挥手：主动关闭方收到FIN后，发送一个ACK给被动关闭方，确认序号为收到序号+1，至此，完成四次挥手。

### 2.TCP、UDP区别，优缺点
TCP提供面向连接的、可靠的数据流传输，而UDP提供的是非面向连接的、不可靠的数据流传输。

TCP传输单位称为TCP报文段，UDP传输单位称为用户数据报。

TCP注重数据安全性，UDP数据传输快，因为不需要连接等待，少了许多操作，但是其安全性却一般。

TCP对应的协议：
FTP、SMTP、POP3、HTTP、Telnet

UDP对应的协议：
DNS、SNMP、TFTP

### 3.在浏览器中输入www.baidu.com 后执行的全部过程

  1、客户端浏览器通过DNS解析到www.baidu.com 的IP地址220.181.27.48，通过这个IP地址找到客户端到服务器的路径。客户端浏览器发起一个HTTP会话到220.161.27.48，然后通过TCP进行封装数据包，输入到网络层。

  2、在客户端的传输层，把HTTP会话请求分成报文段，添加源和目的端口，如服务器使用80端口监听客户端的请求，客户端由系统随机选择一个端口如5000，与服务器进行交换，服务器把相应的请求返回给客户端的5000端口。然后使用IP层的IP地址查找目的端。

  3、客户端的网络层不用关系应用层或者传输层的东西，主要做的是通过查找路由表确定如何到达服务器，期间可能经过多个路由器，这些都是由路由器来完成的工作，我不作过多的描述，无非就是通过查找路由表决定通过那个路径到达服务器。

  4、客户端的链路层，包通过链路层发送到路由器，通过邻居协议查找给定IP地址的MAC地址，然后发送ARP请求查找目的地址，如果得到回应后就可以使用ARP的请求应答交换的IP数据包现在就可以传输了，然后发送IP数据包到达服务器的地址。

### 4.各种协议

ICMP协议：因特网控制报文协议。它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。

TFTP协议：是TCP/IP协议族中的一个用来在客户机与服务器之间进行简单文件传输的协议，提供不复杂、开销不大的文件传输服务。

HTTP协议：超文本传输协议，是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。

NAT协议：网络地址转换属接入广域网(WAN)技术，是一种将私有（保留）地址转化为合法IP地址的转换技术，

DHCP协议：动态主机设置协议(Dynamic Host Configuration Protocol，DHCP)是局域网的一个网络协议，它使用UDP协议工作，主要用途有两个：(1)替内部网络或网络服务供应商自动分配IP地址给用户；(2)是内部网络管理员对所有计算机进行管理的一种手段。DHCP给网络中的主机分配的IP地址，可能是静态IP地址，也可能是动态IP地址。

## 三：操作系统
https://www.cnblogs.com/believe-in-me/p/6603935.html

### 1.进程和线程的区别、关系
进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动，进程是系统进行资源分配和调度的一个独立单位。

线程是进程的一个实体，是CPU调度和分派的基本单位，它是比进程更小的能独立运行的基本单位。线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源（如程序计数器，一组寄存器和栈），但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。一个线程可以创建和撤销另一个线程，同一个进程中的多个线程之间可以并发执行。

进程与应用程序的区别在于应用程序作为一个静态文件存储在计算机系统的硬盘等存储空间中，而进程则是处于动态条件下由操作系统维护的系统资源管理实体。

### 2.产生死锁的必要条件：

　　（1）互斥（mutualexclusion），一个资源每次只能被一个进程使用；

　　（2）不可抢占（nopreemption），进程已获得的资源，在未使用完之前，不能强行剥夺；

　　（3）占有并等待（hold andwait），一个进程因请求资源而阻塞时，对已获得的资源保持不放；

　　（4）环形等待（circularwait），若干进程之间形成一种首尾相接的循环等待资源关系。

　死锁的处理策略：鸵鸟策略、预防策略、避免策略、检测与恢复策略。

### 3.进程同步
进程同步的主要任务：是对多个相关进程在执行次序上进行协调，以使并发执行的诸进程之间能有效地共享资源和相互合作，从而使程序的执行具有可再现性。

　　同步机制遵循的原则：

　　（1）空闲让进；

　　（2）忙则等待（保证对临界区的互斥访问）；

　　（3）有限等待（有限代表有限的时间，避免死等）；

　　（4）让权等待，（当进程不能进入自己的临界区时，应该释放处理机，以免陷入忙等状态）。

### 4.进程间的通信是如何实现的？

　　进程通信，是指进程之间的信息交换（信息量少则一个状态或数值，多者则是成千上万个字节）。因此，对于用信号量进行的进程间的互斥和同步，由于其所交换的信息量少而被归结为低级通信。

　　所谓高级进程通信指：用户可以利用操作系统所提供的一组通信命令传送大量数据的一种通信方式。操作系统隐藏了进程通信的实现细节。或者说，通信过程对用户是透明的。

　　高级通信机制可归结为三大类：

　　（1）共享存储器系统（存储器中划分的共享存储区）；实际操作中对应的是“剪贴板”（剪贴板实际上是系统维护管理的一块内存区域）的通信方式，比如举例如下：word进程按下ctrl+c，在ppt进程按下ctrl+v，即完成了word进程和ppt进程之间的通信，复制时将数据放入到剪贴板，粘贴时从剪贴板中取出数据，然后显示在ppt窗口上。

　　（2）消息传递系统（进程间的数据交换以消息（message）为单位，当今最流行的微内核操作系统中，微内核与服务器之间的通信，无一例外地都采用了消息传递机制。应用举例：邮槽（MailSlot）是基于广播通信体系设计出来的，它采用无连接的不可靠的数据传输。邮槽是一种单向通信机制，创建邮槽的服务器进程读取数据，打开邮槽的客户机进程写入数据。

　　（3）管道通信系统（管道即：连接读写进程以实现他们之间通信的共享文件（pipe文件，类似先进先出的队列，由一个进程写，另一进程读））。实际操作中，管道分为：匿名管道、命名管道。匿名管道是一个未命名的、单向管道，通过父进程和一个子进程之间传输数据。匿名管道只能实现本地机器上两个进程之间的通信，而不能实现跨网络的通信。命名管道不仅可以在本机上实现两个进程间的通信，还可以跨网络实现两个进程间的通信。

## 四：数据库
### 1.数据库索引
https://www.cnblogs.com/aspwebchh/p/6652855.html

    为什么要给表加上主键？

    为什么加索引后会使查询变快？

    为什么加索引后会使写入、修改、删除变慢？

    什么情况下要同时在两个字段上建索引？

想要理解索引原理必须清楚一种数据结构「平衡树」(非二叉)，也就是b tree或者 b+ tree，
重要的事情说三遍：“平衡树，平衡树，平衡树”。
当然， 有的数据库也使用哈希桶作用索引的数据结构 ， 然而， 主流的RDBMS都是把平衡树当做数据表默认的索引数据结构的。

如果给表上了主键，那么表在磁盘上的存储结构就由整齐排列的结构转变成了树状结构，也就是上面说的「平衡树」结构，
换句话说，就是整个表就变成了一个索引。
没错， 再说一遍， 整个表变成了一个索引，也就是所谓的「聚集索引」。
这就是为什么一个表只能有一个主键， 一个表只能有一个「聚集索引」，因为主键的作用就是把「表」的数据格式转换成「索引（平衡树）」的格式放置。

然而， 事物都是有两面的， 索引能让数据库查询数据的速度上升， 而使写入数据的速度下降，原因很简单的，
因为平衡树这个结构必须一直维持在一个正确的状态， 增删改数据都会改变平衡树各节点中的索引数据内容，破坏树结构， 因此，在每次数据改变时， DBMS必须去重新梳理树（索引）的结构以确保它的正确，这会带来不小的性能开销，也就是为什么索引会给查询以外的操作带来副作用的原因。

### 2.范式
1、1NF(第一范式)

第一范式是指数据库表中的每一列都是不可分割的基本数据项，同一列中不能有多个值，即实体中的某个属性不能有多个值或者不能有重复的属性。

2、2NF(第二范式)

第二范式(2NF)要求数据库表中的每个实例或行必须可以被唯一地区分。为实现区分通常需要为表加上一个列，以存储各个实例的唯一标识。

3、3NF(第三范式)

如果关系模型R是第二范式，且每个非主属性都不传递依赖于R的候选键，则称R是第三范式的模式。

4、BCNF(BC范式)

它构建在第三范式的基础上，如果关系模型R是第一范式，且每个属性都不传递依赖于R的候选键，那么称R为BCNF的模式。

5、4NF(第四范式)

设R是一个关系模型，D是R上的多值依赖集合。如果D中存在凡多值依赖X->Y时，X必是R的超键，那么称R是第四范式的模式。

## 五：机器学习、深度学习
### 1.SVM
#### SVM的原理是什么？
SVM是一种二类分类模型。它的基本模型是在特征空间中寻找间隔最大化的分离超平面的线性分类器。（间隔最大是它有别于感知机）

（1）当训练样本线性可分时，通过硬间隔最大化，学习一个线性分类器，即线性可分支持向量机；

（2）当训练数据近似线性可分时，引入松弛变量，通过软间隔最大化，学习一个线性分类器，即线性支持向量机；

（3）当训练数据线性不可分时，通过使用核技巧及软间隔最大化，学习非线性支持向量机。


#### SVM为什么采用间隔最大化？
当训练数据线性可分时，存在无穷个分离超平面可以将两类数据正确分开。

感知机利用误分类最小策略，求得分离超平面，不过此时的解有无穷多个。

线性可分支持向量机利用间隔最大化求得最优分离超平面，这时，解是唯一的。另一方面，此时的分隔超平面所产生的分类结果是最鲁棒的，对未知实例的泛化能力最强。

然后应该借此阐述，几何间隔，函数间隔，及从函数间隔—>求解最小化1/2 ||w||^2 时的w和b。即线性可分支持向量机学习算法—最大间隔法的由来。

#### 为什么要将求解SVM的原始问题转换为其对偶问题？
一、是对偶问题往往更易求解（当我们寻找约束存在时的最优点的时候，约束的存在虽然减小了需要搜寻的范围，但是却使问题变得更加复杂。为了使问题变得易于处理，我们的方法是把目标函数和约束全部融入一个新的函数，即拉格朗日函数，再通过这个函数来寻找最优点。）

二、自然引入核函数，进而推广到非线性分类问题。

#### 为什么SVM要引入核函数？
当样本在原始空间线性不可分时，可将样本从原始空间映射到一个更高维的特征空间，使得样本在这个特征空间内线性可分。

在学习预测中，只定义核函数K(x,y)，而不是显式的定义映射函数ϕ。因为特征空间维数可能很高，甚至可能是无穷维，因此直接计算ϕ(x)·ϕ(y)是比较困难的。相反，直接计算K(x,y)比较容易（即直接在原来的低维空间中进行计算，而不需要显式地写出映射后的结果）。

核函数的定义：K(x,y)=<ϕ(x),ϕ(y)>，即在特征空间的内积等于它们在原始样本空间中通过核函数K计算的结果。

除了 SVM 之外，任何将计算表示为数据点的内积的方法，都可以使用核方法进行非线性扩展。


#### 为什么SVM对缺失数据敏感？
这里说的缺失数据是指缺失某些特征数据，向量数据不完整。SVM没有处理缺失值的策略（决策树有）。而SVM希望样本在特征空间中线性可分，所以特征空间的好坏对SVM的性能很重要。缺失特征数据将影响训练结果的好坏。

#### SVM如何处理多分类问题？
一般有两种做法：一种是直接法，直接在目标函数上修改，将多个分类面的参数求解合并到一个最优化问题里面。看似简单但是计算量却非常的大。

另外一种做法是间接法：对训练器进行组合。其中比较典型的有一对一，和一对多。

一对多，就是对每个类都训练出一个分类器，由svm是二分类，所以将此而分类器的两类设定为目标类为一类，其余类为另外一类。这样针对k个类可以训练出k个分类器，当有一个新的样本来的时候，用这k个分类器来测试，那个分类器的概率高，那么这个样本就属于哪一类。这种方法效果不太好，bias比较高。

svm一对一法（one-vs-one），针对任意两个类训练出一个分类器，如果有k类，一共训练出C(2,k) 个分类器，这样当有一个新的样本要来的时候，用这C(2,k) 个分类器来测试，每当被判定属于某一类的时候，该类就加一，最后票数最多的类别被认定为该样本的类。

### 2.梯度下降
#### 批量梯度下降法（Batch Gradient Descent，简称BGD）
是梯度下降法最原始的形式，它的具体思路是在更新每一参数时都使用所有的样本来进行更新。

优点：全局最优解；易于并行实现；

缺点：当样本数目很多时，训练过程会很慢。

#### 随机梯度下降法(SGD)
它的具体思路是在更新每一参数时都使用一个样本来进行更新。

优点：训练速度快；

缺点：准确度下降，并不是全局最优；不易于并行实现。

#### 小批量梯度下降法（Mini-batch Gradient Descent，MBGD）
它的具体思路是在更新每一参数时都使用一部分样本来进行更新。

如果样本量比较小，采用批量梯度下降算法。如果样本太大，或者在线算法，使用随机梯度下降算法。在实际的一般情况下，采用小批量梯度下降算法。

### 3.防止过拟合

正则化:L1、L2
L1正则化是指权值向量w中各个元素的绝对值之和，通常表示为||w||1

L2正则化是指权值向量w中各个元素的平方和然后再求平方根（可以看到Ridge回归的L2正则化项有平方符号），通常表示为||w||2

L1正则化可以产生稀疏权值矩阵，即产生一个稀疏模型，可以用于特征选择

L2正则化可以防止模型过拟合（overfitting）；一定程度上，L1也可以防止过拟合



dropout

early-stopping

数据增强

### 4.偏差、方差

    低偏差低方差时，是我们所追求的效果，此时预测值正中靶心(最接近真实值)，且比较集中(方差小)。
    低偏差高方差时，预测值基本落在真实值周围，但很分散，此时方差较大，说明模型的稳定性不够好。
    高偏差低方差时，预测值与真实值有较大距离，但此时值很集中，方差小；模型的稳定性较好，但预测准确率不高，处于“一如既往地预测不准”的状态。
    高偏差高方差时，是我们最不想看到的结果，此时模型不仅预测不准确，而且还不稳定，每次预测的值都差别比较大。


### 5.梯度消失、爆炸

### 6.加速训练、最小化损失

Momentum、RMSprop、Adam

学习率衰减

Batch Normalization

### 7.GRU、LSTM

### 8.决策树：ID3、C4.5、CART
ID3:信息增益。多值偏向。

C4.5:信息增益率。

CART:基尼指数。

ID3算法缺点：

    ID3算法不能处理具有连续值的属性
    ID3算法不能处理属性具有缺失值的样本
    算法会生成很深的树，容易产生过拟合现象
    算法一般会优先选择有较多属性值的特征，因为属性值多的特征会有相对较大的信息增益

C4.5弥补了ID3中不能处理特征属性值连续的问题。
但是，对连续属性值需要扫描排序，会使C4.5性能下降。

### 9.Ensemble Learning：Bagging、Boosting、Statcking

AdaBoost、GDBT、Xtgboost、lightGBM

### 10.贝叶斯、朴素贝叶斯

朴素贝叶斯：各特征独立

### 11.聚类
K-MEANS、DBSCAN、Birch、MEAN-SHIFT

K-MEANS影响结果的因素：k值、中心初始值。

K-MEANS优点：简单。
K-MEANS缺点：对异常值敏感;需要提前确定k值;不一定是全局最优，只能保证局部最优;
结果不稳定。

### 12.PCA、LDA
https://blog.csdn.net/zjm750617105/article/details/52104850

区别：
PCA是从特征的角度协方差角度：
求出协方差矩阵的特征值和特征向量，然后将特征向量按特征值的大小排序取出前K行组成矩阵P（这个P就是我们对角化协方差矩阵的时所使用的P, 具体的可以看看矩阵对角化的过程），
这个P就是一组正交变化基， 然后将原始的矩阵X，左乘P，也就是将X变换到P组成的正交基中，然后PX＝Y就是降维后的矩阵。

而LDA则是在已知样本的类标注， 希望投影到新的基后使得不同的类别之间的数据点的距离更大，同一类别的数据点更紧凑。

### 13.核函数
线性核、多项式核、径向基核、sigmoid核、高斯核

### 14.判别式、生成式
对于输入x，类别标签y：
产生式模型估计它们的联合概率分布P(x,y)，
判别式模型估计条件概率分布P(y|x)。

产生式模型可以根据贝叶斯公式得到判别式模型，但反过来不行。

判别式模型常见的主要有：

    Logistic Regression
    SVM
    Traditional Neural Networks
    Nearest Neighbor
    CRF
    Linear Discriminant Analysis
    Boosting
    Linear Regression

产生式模型常见的主要有：

    Gaussians
    Naive Bayes
    Mixtures of Multinomials
    Mixtures of Gaussians
    Mixtures of Experts
    HMMs
    Sigmoidal Belief Networks, Bayesian Networks
    Markov Random Fields
    Latent Dirichlet Allocation


### 15.EM算法
EM算法是为了解决“最大似然估计”中更复杂的情形而存在的.
我们知道极大似然估计是求解实现结果的最佳参数θ，但极大似然估计需要面临的概率分布只有一个或者知道结果是通过哪个概率分布实现的，只不过你不知道这个概率分布的参数。
而如果概率分布有多个呢或者你不知道结果是通过哪个概率分布实现的？于是别说去确定“这些概率分布”的最佳参数了，我们连最终结果是根据哪个概率分布得出来的都不知道，这就是EM算法要面临的情况了。

EM算法是一种解决存在隐含变量优化问题的有效方法。
EM算法是期望极大(Expectation Maximization)算法的简称，EM算法是一种迭代型的算法，在每一次的迭代过程中，主要分为两步：即求期望(Expectation)步骤和最大化(Maximization)步骤。
猜（E-step）,反思（M-step）,重复；

## 六：数学
### 1.先验概率、后验概率

### 2.分布

### 3.检验

### 4.傅里叶变换

### 5.泰勒展开

### 6.对偶问题

### 7.正定矩阵
（1）广义定义：设M是n阶方阵，如果对任何非零向量z，都有zTMz> 0，其中zT 表示z的转置，就称M正定矩阵。

例如：B为n阶矩阵，E为单位矩阵，a为正实数。aE+B在a充分大时，aE+B为正定矩阵。（B必须为对称阵）

（2）狭义定义：一个n阶的实对称矩阵M是正定的的条件是当且仅当对于所有的非零实系数向量z，都有zTMz> 0。其中zT表示z的转置。




## 七：大数据
hadoop：
https://blog.csdn.net/qq_15103197/article/details/78404541?fps=1&locationNum=7

https://www.cnblogs.com/juncaoit/p/6421806.html