## 1.进程间通行的方式
**1.管道pipe**：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。

**2.命名管道FIFO**：有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。

**3.消息队列MessageQueue**：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。

**4.共享存储SharedMemory**：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。

**5.信号量Semaphore**：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。

**6.套接字Socket**：套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同及其间的进程通信。

**7.信号sinal**： 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。

## 2.python中无switch-case语句
不同于我用过的其它编程语言，Python 没有 switch / case 语句。为了实现它，我们可以使用字典映射：
```python
    def numbers_to_strings(argument):
        switcher = {
            0: "zero",
            1: "one",
            2: "two",
        }
        return switcher.get(argument, "nothing")
```

## 3.死锁的必要条件

**互斥条件**即某个资源在一段时间内只能由一个进程占有，不能同时被两个或两个以上的进程占有。这种独占资源如CD-ROM驱动器，打印机等等，必须在占有该资源的进程主动释放它之后，其它进程才能占有该资源。这是由资源本身的属性所决定的。如独木桥就是一种独占资源，两方的人不能同时过桥。

**不可抢占条件**进程所获得的资源在未使用完毕之前，资源申请者不能强行地从资源占有者手中夺取资源，而只能由该资源的占有者进程自行释放。如过独木桥的人不能强迫对方后退，也不能非法地将对方推下桥，必须是桥上的人自己过桥后空出桥面（即主动释放占有资源），对方的人才能过桥。

**占有且申请条件**进程至少已经占有一个资源，但又申请新的资源；由于该资源已被另外进程占有，此时该进程阻塞；但是，它在等待新资源之时，仍继续占用已占有的资源。还以过独木桥为例，甲乙两人在桥上相遇。甲走过一段桥面（即占有了一些资源），还需要走其余的桥面（申请新的资源），但那部分桥面被乙占有（乙走过一段桥面）。甲过不去，前进不能，又不后退；乙也处于同样的状况。

**循环等待条件**存在一个进程等待序列{P1，P2，...，Pn}，其中P1等待P2所占有的某一资源，P2等待P3所占有的某一源，......，而Pn等待P1所占有的的某一资源，形成一个进程循环等待环。就像前面的过独木桥问题，甲等待乙占有的桥面，而乙又等待甲占有的桥面，从而彼此循环等待。

## 4.卷积的计算
矩阵的乘法。

## 5.KNN和K-MEANS
1.KNN是有监督学习，K-MEANS是无监督学习;
2.KNN可以不用训练参数，就能预测新样本

## 6.SVM的核函数有哪些
**线性核函数**
	κ(x,xi)=x⋅xi
线性核，主要用于线性可分的情况，我们可以看到特征空间到输入空间的维度是一样的，其参数少速度快，对于线性可分数据，其分类效果很理想，因此我们通常首先尝试用线性核函数来做分类，看看效果如何，如果不行再换别的

**多项式核函数**
	κ(x,xi)=((x⋅xi)+1)d
多项式核函数可以实现将低维的输入空间映射到高纬的特征空间，但是多项式核函数的参数多，当多项式的阶数比较高的时候，核矩阵的元素值将趋于无穷大或者无穷小，计算复杂度会大到无法计算。

**高斯（RBF）核函数**
	κ(x,xi)=exp(−||x−xi||2δ2)
高斯径向基函数是一种局部性强的核函数，其可以将一个样本映射到一个更高维的空间内，该核函数是应用最广的一个，无论大样本还是小样本都有比较好的性能，而且其相对于多项式核函数参数要少，因此大多数情况下在不知道用什么核函数的时候，优先使用高斯核函数。

**sigmoid核函数**
	κ(x,xi)=tanh(η<x,xi>+θ)
采用sigmoid核函数，支持向量机实现的就是一种多层神经网络。

## 7.生成模型
常见的生成方法有混合高斯模型、朴素贝叶斯法和隐形马尔科夫模型等，

常见的判别方法有SVM、LR等。

## 8.Recall、Precision、ROC、AUC

在二元分类模型的预测结果有四种，以判断人是否有病为例：

- 真阳性（TP）：诊断为有，实际上也有病。
- 伪阳性（FP）：诊断为有，实际却没有病。
- 真阴性（TN）：诊断为没有，实际上也没有病。
- 伪阴性（FN）：诊断为没有，实际却有病。

ROC空间将伪阳性率（FPR）定义为X轴，真阳性率（TPR）定义为Y轴。TPR：在所有实际为阳性的样本中，被正确地判断为阳性之比率，TPR=TP/（TP+FN） 。FPR：在所有实际为阴性的样本中，被错误地判断为阳性之比率，FPR=FP/（FP+TN）。

对于二分类问题另一个常用的评价指标是精确率（precision）与召回率（recall）以及F1值。精确率表示在预测为阳性的样本中，真正有阳性的样本所占的比例。精确率的定义为P=TP/（TP+FP）。召回率表示所有真正呈阳性的样本中，预测为阳性所占的比例。召回率的定义为R=TP/（TP+FN），F1值是精确率和召回率的调和均值，公式为F1=2PR（P+R）。精确率和召回率都高时，F1值也会高。通常情况下，Precision与Recall是相互矛盾的。

AUC为ROC曲线下的面积，它的面积不会大于1，由于ROC曲线一般都处于直线y=x的上方，因此AUC的取值范围通常在(0.5，1)之间。由于ROC曲线不能很好的看出分类器模型的好坏，因此采用AUC值来进行分类器模型的评估与比较。通常AUC值越大，分类器性能越好。

## 9.Logistic Regression同时使用L1、L2正则化有什么效果
特征选择+防过拟合

## 10.矩阵计算效率
ABC三个矩阵，大小分别为m×n，n×p，p×q，其中m< n< p< q.

一个m*n的矩阵A乘以n*q的矩阵B。我们会用矩阵A的第一行，乘以矩阵B的第一列并相加。这一运算需要耗费n次乘法以及n-1次加法，矩阵B有q列，矩阵A有m行，所以A*B的复杂度为m*(2n-1)*q。

## 11.什么是无监督学习，常用的无监督方法有哪些？

## 12.常用的深度学习模型以及他们的结构？
DNN、CNN、RNN、LSTM。

## 13.拥有少量样本怎么进行深度学习？
迁移学习。